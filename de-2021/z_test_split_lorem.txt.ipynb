{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# (8 cores, 16gb per machine) x 5 = 40 cores\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.87:7077\") \\\n",
    "        .appName(\"playsplitLorem\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",4)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, \n"
     ]
    }
   ],
   "source": [
    "lines = spark_context.textFile(\"hdfs://192.168.2.87:9000/lorem-split.txt\")\n",
    "print(lines.first())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "# spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '\"Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, \\ntotam rem aperiam,\\neaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo.\\n'),\n",
       " (223,\n",
       "  'Nemo enim ipsam voluptatem quia voluptas sit\\n aspernatur aut odit aut fugit, sed\\n  quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. \\n'),\n",
       " (387,\n",
       "  'Neque porro quisquam est, qui dolorem ipsum\\n quia dolor sit amet, consectetur, adipisci velit, sed quia\\n  non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim \\n'),\n",
       " (601,\n",
       "  'ad minima veniam, quis\\n nostrum exercitationem ullam corporis suscipit laboriosam\\n , nisi ut aliquid ex ea commodi consequatur? \\n')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "lorem_split = spark_context.newAPIHadoopFile(\n",
    "    'hdfs://192.168.2.87:9000/lorem-split.txt',\n",
    "    'org.apache.hadoop.mapreduce.lib.input.TextInputFormat',\n",
    "    'org.apache.hadoop.io.LongWritable',\n",
    "    'org.apache.hadoop.io.Text',\n",
    "    conf={'textinputformat.record.delimiter': 'abcd\\n'}\n",
    ")\n",
    "\n",
    "lorem_split.take(4)\n",
    "\n",
    "\n",
    "# (retrosheet\n",
    "#     .filter(itemgetter(1))\n",
    "#     .values()\n",
    "#     .filter(lambda x: x)\n",
    "#     .map(lambda v: (\n",
    "#         v if v.startswith('id') else 'id,{0}'.format(v)).splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
