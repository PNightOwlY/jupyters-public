{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from operator import add\n",
    "\n",
    "# New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"blameyben_lecture1_hdfs_example\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.\n",
      "total words= 1716\n"
     ]
    }
   ],
   "source": [
    "# The same example, this time using map and reduce from the Spark API, and loading the text file from HDFS.\n",
    "\n",
    "lines = spark_context.textFile(\"hdfs://192.168.2.113:9000/king-dream.txt\")\n",
    "print(lines.first())\n",
    "\n",
    "words = lines.map(lambda line: line.split(' '))\n",
    "\n",
    "word_counts = words.map(lambda w: len(w))\n",
    "\n",
    "total_words = word_counts.reduce(add)\n",
    "\n",
    "print(f'total words= {total_words}')  \n",
    "\n",
    "# ... the same number of words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am happy to join with you today in what will go down in history as the greatest demonstration for freedom in the history of our nation.',\n",
       " '',\n",
       " 'Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of withering injustice. It came as a joyous daybreak to end the long night of their captivity.',\n",
       " '',\n",
       " \"But one hundred years later, the Negro still is not free. One hundred years later, the life of the Negro is still sadly crippled by the manacles of segregation and the chains of discrimination. One hundred years later, the Negro lives on a lonely island of poverty in the midst of a vast ocean of material prosperity. One hundred years later, the Negro is still languished in the corners of American society and finds himself an exile in his own land. And so we've come here today to dramatize a shameful condition.\",\n",
       " '',\n",
       " 'In a sense we\\'ve come to our nation\\'s capital to cash a check. When the architects of our republic wrote the magnificent words of the Constitution and the Declaration of Independence, they were signing a promissory note to which every American was to fall heir. This note was a promise that all men, yes, black men as well as white men, would be guaranteed the \"unalienable Rights\" of \"Life, Liberty and the pursuit of Happiness.\" It is obvious today that America has defaulted on this promissory note, insofar as her citizens of color are concerned. Instead of honoring this sacred obligation, America has given the Negro people a bad check, a check which has come back marked \"insufficient funds.\"',\n",
       " '',\n",
       " \"But we refuse to believe that the bank of justice is bankrupt. We refuse to believe that there are insufficient funds in the great vaults of opportunity of this nation. And so, we've come to cash this check, a check that will give us upon demand the riches of freedom and the security of justice.\",\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'happy', 'to', 'join', 'with', 'you', 'today', 'in', 'what', 'will', 'go', 'down', 'in', 'history', 'as', 'the', 'greatest', 'demonstration', 'for', 'freedom', 'in', 'the', 'history', 'of', 'our', 'nation.']\n"
     ]
    }
   ],
   "source": [
    "lines_splitted = lines.map(lambda line: line.split(' '))\n",
    "print(lines_splitted.first())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'happy',\n",
       " 'to',\n",
       " 'join',\n",
       " 'with',\n",
       " 'you',\n",
       " 'today',\n",
       " 'in',\n",
       " 'what',\n",
       " 'will',\n",
       " 'go',\n",
       " 'down',\n",
       " 'in',\n",
       " 'history',\n",
       " 'as',\n",
       " 'the',\n",
       " 'greatest',\n",
       " 'demonstration',\n",
       " 'for',\n",
       " 'freedom',\n",
       " 'in',\n",
       " 'the',\n",
       " 'history',\n",
       " 'of',\n",
       " 'our',\n",
       " 'nation.',\n",
       " '',\n",
       " 'Five',\n",
       " 'score',\n",
       " 'years',\n",
       " 'ago,',\n",
       " 'a',\n",
       " 'great',\n",
       " 'American,',\n",
       " 'in',\n",
       " 'whose',\n",
       " 'symbolic',\n",
       " 'shadow',\n",
       " 'we',\n",
       " 'stand',\n",
       " 'today,',\n",
       " 'signed',\n",
       " 'the',\n",
       " 'Emancipation',\n",
       " 'Proclamation.',\n",
       " 'This',\n",
       " 'momentous',\n",
       " 'decree',\n",
       " 'came',\n",
       " 'as',\n",
       " 'a',\n",
       " 'great',\n",
       " 'beacon',\n",
       " 'light',\n",
       " 'of',\n",
       " 'hope',\n",
       " 'to',\n",
       " 'millions',\n",
       " 'of',\n",
       " 'Negro',\n",
       " 'slaves',\n",
       " 'who',\n",
       " 'had',\n",
       " 'been',\n",
       " 'seared',\n",
       " 'in',\n",
       " 'the',\n",
       " 'flames',\n",
       " 'of',\n",
       " 'withering',\n",
       " 'injustice.',\n",
       " 'It',\n",
       " 'came',\n",
       " 'as',\n",
       " 'a',\n",
       " 'joyous',\n",
       " 'daybreak',\n",
       " 'to',\n",
       " 'end',\n",
       " 'the',\n",
       " 'long',\n",
       " 'night',\n",
       " 'of',\n",
       " 'their',\n",
       " 'captivity.',\n",
       " '',\n",
       " 'But',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'years',\n",
       " 'later,',\n",
       " 'the',\n",
       " 'Negro',\n",
       " 'still',\n",
       " 'is',\n",
       " 'not',\n",
       " 'free.',\n",
       " 'One',\n",
       " 'hundred']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 54992)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Note, we're in Python, but using Java naming conventions!\n",
    "\n",
    "all_words = lines.flatMap(lambda line: line.split(' '))\n",
    "fv.take(100)\n",
    "# all_words.filter(lambda word: word.startswith('d'))\\\n",
    "#      .take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception happened during processing of request from ('127.0.0.1', 33978)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.8/socketserver.py\", line 720, in __init__\n",
      "    self.handle()\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 268, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 241, in poll\n",
      "    if func():\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/accumulators.py\", line 245, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/home/ubuntu/.local/lib/python3.8/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# release the cores for another application!\n",
    "#spark_context.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
